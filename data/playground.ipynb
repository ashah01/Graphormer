{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ogb.graphproppred import PygGraphPropPredDataset\n",
    "import torch\n",
    "import numpy as np\n",
    "import math\n",
    "import torch.nn as nn\n",
    "from functools import lru_cache\n",
    "import pyximport\n",
    "pyximport.install(setup_args={\"include_dirs\": np.get_include()})\n",
    "from algos import floyd_warshall\n",
    "import torch_geometric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_single_emb(x, offset: int = 512):\n",
    "    feature_num = x.size(1) if len(x.size()) > 1 else 1\n",
    "    feature_offset = 1 + torch.arange(0, feature_num * offset, offset, dtype=torch.long)\n",
    "    x = x + feature_offset\n",
    "    return x\n",
    "\n",
    "def preprocess_item(item):\n",
    "    edge_attr, edge_index, x = item.edge_attr, item.edge_index, item.x\n",
    "    N = x.size(0)\n",
    "    x = convert_to_single_emb(x)\n",
    "\n",
    "    # node adj matrix [N, N] bool\n",
    "    adj = torch.zeros([N, N], dtype=torch.bool)\n",
    "    adj[edge_index[0, :], edge_index[1, :]] = True\n",
    "\n",
    "    # edge feature here\n",
    "    # if len(edge_attr.size()) == 1:\n",
    "    #     edge_attr = edge_attr[:, None]\n",
    "    # attn_edge_type = torch.zeros([N, N, edge_attr.size(-1)], dtype=torch.long)\n",
    "    # attn_edge_type[edge_index[0, :], edge_index[1, :]] = (\n",
    "    #     convert_to_single_emb(edge_attr) + 1\n",
    "    # )\n",
    "\n",
    "    shortest_path_result, path = floyd_warshall(adj.numpy())\n",
    "    # max_dist = np.amax(shortest_path_result)\n",
    "    # edge_input = algos.gen_edge_input(max_dist, path, attn_edge_type.numpy())\n",
    "    spatial_pos = torch.from_numpy((shortest_path_result)).long()\n",
    "    attn_bias = torch.zeros([N + 1, N + 1], dtype=torch.float)  # with graph token\n",
    "\n",
    "    # combine\n",
    "    # item.x = x\n",
    "    item.attn_bias = attn_bias\n",
    "    # # item.attn_edge_type = attn_edge_type\n",
    "    # item.spatial_pos = spatial_pos\n",
    "    # item.degree = adj.long().sum(dim=1).view(-1)\n",
    "    # item.edge_input = torch.from_numpy(edge_input).long()\n",
    "\n",
    "    return item\n",
    "\n",
    "\n",
    "class MyPygGraphPropPredDataset(PygGraphPropPredDataset):\n",
    "\n",
    "    @lru_cache(maxsize=16)\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.get(self.indices()[idx])\n",
    "        # item.idx = idx\n",
    "        # item.y = item.y.reshape(-1)\n",
    "        return preprocess_item(item)\n",
    "\n",
    "dataset = MyPygGraphPropPredDataset('ogbg-molhiv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from collections.abc import Mapping, Sequence\n",
    "from typing import Any, List, Optional, Tuple, Union\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch_sparse import SparseTensor, cat\n",
    "\n",
    "from torch_geometric.data.data import BaseData\n",
    "from torch_geometric.data.storage import BaseStorage, NodeStorage\n",
    "\n",
    "\n",
    "def collate(\n",
    "    cls,\n",
    "    data_list: List[BaseData],\n",
    "    increment: bool = True,\n",
    "    add_batch: bool = True,\n",
    "    follow_batch: Optional[Union[List[str]]] = None,\n",
    "    exclude_keys: Optional[Union[List[str]]] = None,\n",
    ") -> Tuple[BaseData, Mapping, Mapping]:\n",
    "    # Collates a list of `data` objects into a single object of type `cls`.\n",
    "    # `collate` can handle both homogeneous and heterogeneous data objects by\n",
    "    # individually collating all their stores.\n",
    "    # In addition, `collate` can handle nested data structures such as\n",
    "    # dictionaries and lists.\n",
    "\n",
    "    if not isinstance(data_list, (list, tuple)):\n",
    "        # Materialize `data_list` to keep the `_parent` weakref alive.\n",
    "        data_list = list(data_list)\n",
    "\n",
    "    if cls != data_list[0].__class__:\n",
    "        out = cls(_base_cls=data_list[0].__class__)  # Dynamic inheritance.\n",
    "    else:\n",
    "        out = cls()\n",
    "\n",
    "    # Create empty stores:\n",
    "    out.stores_as(data_list[0])\n",
    "\n",
    "    follow_batch = set(follow_batch or [])\n",
    "    exclude_keys = set(exclude_keys or [])\n",
    "\n",
    "    # Group all storage objects of every data object in the `data_list` by key,\n",
    "    # i.e. `key_to_store_list = { key: [store_1, store_2, ...], ... }`:\n",
    "    key_to_stores = defaultdict(list)\n",
    "    for data in data_list:\n",
    "        for store in data.stores:\n",
    "            key_to_stores[store._key].append(store)\n",
    "\n",
    "    # With this, we iterate over each list of storage objects and recursively\n",
    "    # collate all its attributes into a unified representation:\n",
    "\n",
    "    # We maintain two additional dictionaries:\n",
    "    # * `slice_dict` stores a compressed index representation of each attribute\n",
    "    #    and is needed to re-construct individual elements from mini-batches.\n",
    "    # * `inc_dict` stores how individual elements need to be incremented, e.g.,\n",
    "    #   `edge_index` is incremented by the cumulated sum of previous elements.\n",
    "    #   We also need to make use of `inc_dict` when re-constructuing individual\n",
    "    #   elements as attributes that got incremented need to be decremented\n",
    "    #   while separating to obtain original values.\n",
    "    device = None\n",
    "    slice_dict, inc_dict = defaultdict(dict), defaultdict(dict)\n",
    "    for out_store in out.stores:\n",
    "        key = out_store._key\n",
    "        stores = key_to_stores[key]\n",
    "        for attr in stores[0].keys():\n",
    "            \n",
    "            if attr == 'attn_bias': # TEST\n",
    "                continue\n",
    "\n",
    "            if attr in exclude_keys:  # Do not include top-level attribute.\n",
    "                continue\n",
    "            \n",
    "            values = [store[attr] for store in stores]\n",
    "\n",
    "            # The `num_nodes` attribute needs special treatment, as we need to\n",
    "            # sum their values up instead of merging them to a list:\n",
    "            if attr == 'num_nodes':\n",
    "                out_store._num_nodes = values\n",
    "                out_store.num_nodes = sum(values)\n",
    "                continue\n",
    "\n",
    "            # Skip batching of `ptr` vectors for now:\n",
    "            if attr == 'ptr':\n",
    "                continue\n",
    "            \n",
    "\n",
    "            # Collate attributes into a unified representation:\n",
    "            value, slices, incs = _collate(attr, values, data_list, stores,\n",
    "                                           increment)\n",
    "            if isinstance(value, Tensor) and value.is_cuda:\n",
    "                device = value.device\n",
    "\n",
    "            out_store[attr] = value\n",
    "            if key is not None:\n",
    "                slice_dict[key][attr] = slices\n",
    "                inc_dict[key][attr] = incs\n",
    "            else:\n",
    "                slice_dict[attr] = slices\n",
    "                inc_dict[attr] = incs\n",
    "\n",
    "            # Add an additional batch vector for the given attribute:\n",
    "            if (attr in follow_batch and isinstance(slices, Tensor)\n",
    "                    and slices.dim() == 1):\n",
    "                repeats = slices[1:] - slices[:-1]\n",
    "                batch = repeat_interleave(repeats.tolist(), device=device)\n",
    "                out_store[f'{attr}_batch'] = batch\n",
    "\n",
    "        # In case the storage holds node, we add a top-level batch vector it:\n",
    "        if (add_batch and isinstance(stores[0], NodeStorage)\n",
    "                and stores[0].can_infer_num_nodes):\n",
    "            repeats = [store.num_nodes for store in stores]\n",
    "            out_store.batch = repeat_interleave(repeats, device=device)\n",
    "            out_store.ptr = cumsum(torch.tensor(repeats, device=device))\n",
    "\n",
    "    return out, slice_dict, inc_dict\n",
    "\n",
    "\n",
    "def _collate(\n",
    "    key: str,\n",
    "    values: List[Any],\n",
    "    data_list: List[BaseData],\n",
    "    stores: List[BaseStorage],\n",
    "    increment: bool,\n",
    ") -> Tuple[Any, Any, Any]:\n",
    "\n",
    "    elem = values[0]\n",
    "\n",
    "    if isinstance(elem, Tensor):\n",
    "        # Concatenate a list of `torch.Tensor` along the `cat_dim`.\n",
    "        # NOTE: We need to take care of incrementing elements appropriately.\n",
    "        cat_dim = data_list[0].__cat_dim__(key, elem, stores[0])\n",
    "        if cat_dim is None or elem.dim() == 0:\n",
    "            values = [value.unsqueeze(0) for value in values]\n",
    "        slices = cumsum([value.size(cat_dim or 0) for value in values])\n",
    "        if increment:\n",
    "            incs = get_incs(key, values, data_list, stores)\n",
    "            if incs.dim() > 1 or int(incs[-1]) != 0:\n",
    "                values = [\n",
    "                    value + inc.to(value.device)\n",
    "                    for value, inc in zip(values, incs)\n",
    "                ]\n",
    "        else:\n",
    "            incs = None\n",
    "\n",
    "        if torch.utils.data.get_worker_info() is not None:\n",
    "            # Write directly into shared memory to avoid an extra copy:\n",
    "            numel = sum(value.numel() for value in values)\n",
    "            storage = elem.storage()._new_shared(numel)\n",
    "            out = elem.new(storage)\n",
    "        else:\n",
    "            out = None\n",
    "\n",
    "        value = torch.cat(values, dim=cat_dim or 0, out=out)\n",
    "        return value, slices, incs\n",
    "\n",
    "    elif isinstance(elem, SparseTensor) and increment:\n",
    "        # Concatenate a list of `SparseTensor` along the `cat_dim`.\n",
    "        # NOTE: `cat_dim` may return a tuple to allow for diagonal stacking.\n",
    "        cat_dim = data_list[0].__cat_dim__(key, elem, stores[0])\n",
    "        cat_dims = (cat_dim, ) if isinstance(cat_dim, int) else cat_dim\n",
    "        repeats = [[value.size(dim) for dim in cat_dims] for value in values]\n",
    "        slices = cumsum(repeats)\n",
    "        value = cat(values, dim=cat_dim)\n",
    "        return value, slices, None\n",
    "\n",
    "    elif isinstance(elem, (int, float)):\n",
    "        # Convert a list of numerical values to a `torch.Tensor`.\n",
    "        value = torch.tensor(values)\n",
    "        if increment:\n",
    "            incs = get_incs(key, values, data_list, stores)\n",
    "            if int(incs[-1]) != 0:\n",
    "                value.add_(incs)\n",
    "        else:\n",
    "            incs = None\n",
    "        slices = torch.arange(len(values) + 1)\n",
    "        return value, slices, incs\n",
    "\n",
    "    elif isinstance(elem, Mapping):\n",
    "        # Recursively collate elements of dictionaries.\n",
    "        value_dict, slice_dict, inc_dict = {}, {}, {}\n",
    "        for key in elem.keys():\n",
    "            value_dict[key], slice_dict[key], inc_dict[key] = _collate(\n",
    "                key, [v[key] for v in values], data_list, stores, increment)\n",
    "        return value_dict, slice_dict, inc_dict\n",
    "\n",
    "    elif (isinstance(elem, Sequence) and not isinstance(elem, str)\n",
    "          and isinstance(elem[0], (Tensor, SparseTensor))):\n",
    "        # Recursively collate elements of lists.\n",
    "        value_list, slice_list, inc_list = [], [], []\n",
    "        for i in range(len(elem)):\n",
    "            value, slices, incs = _collate(key, [v[i] for v in values],\n",
    "                                           data_list, stores, increment)\n",
    "            value_list.append(value)\n",
    "            slice_list.append(slices)\n",
    "            inc_list.append(incs)\n",
    "        return value_list, slice_list, inc_list\n",
    "\n",
    "    else:\n",
    "        # Other-wise, just return the list of values as it is.\n",
    "        slices = torch.arange(len(values) + 1)\n",
    "        return values, slices, None\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "\n",
    "\n",
    "def repeat_interleave(\n",
    "    repeats: List[int],\n",
    "    device: Optional[torch.device] = None,\n",
    ") -> Tensor:\n",
    "    outs = [torch.full((n, ), i, device=device) for i, n in enumerate(repeats)]\n",
    "    return torch.cat(outs, dim=0)\n",
    "\n",
    "\n",
    "def cumsum(value: Union[Tensor, List[int]]) -> Tensor:\n",
    "    if not isinstance(value, Tensor):\n",
    "        value = torch.tensor(value)\n",
    "    out = value.new_empty((value.size(0) + 1, ) + value.size()[1:])\n",
    "    out[0] = 0\n",
    "    torch.cumsum(value, 0, out=out[1:])\n",
    "    return out\n",
    "\n",
    "\n",
    "def get_incs(key, values: List[Any], data_list: List[BaseData],\n",
    "             stores: List[BaseStorage]) -> Tensor:\n",
    "    repeats = [\n",
    "        data.__inc__(key, value, store)\n",
    "        for value, data, store in zip(values, data_list, stores)\n",
    "    ]\n",
    "    if isinstance(repeats[0], Tensor):\n",
    "        repeats = torch.stack(repeats, dim=0)\n",
    "    else:\n",
    "        repeats = torch.tensor(repeats)\n",
    "    return cumsum(repeats[:-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "value, slices, inc = collate(cls=dataset[0].__class__, data_list=[dataset[0], dataset[1], dataset[2], dataset[3], dataset[4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 244], edge_attr=[244, 3], x=[113, 9], y=[5, 1], num_nodes=113, batch=[113], ptr=[6])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   1,   1,   2,   2,   3,   3,   4,   4,   5,   5,   6,   6,   7,\n",
       "           7,   8,   6,   9,   4,  10,  10,  11,  11,  12,  12,  13,  11,  14,\n",
       "          14,  15,  15,  16,  16,  17,  15,  18,   9,   2,  18,   4,  19,  20,\n",
       "          20,  21,  21,  22,  22,  23,  23,  24,  24,  25,  25,  26,  19,  27,\n",
       "          27,  28,  28,  29,  29,  30,  30,  31,  31,  32,  32,  33,  33,  34,\n",
       "          34,  35,  35,  36,  36,  37,  37,  38,  38,  39,  31,  40,  40,  41,\n",
       "          41,  42,  42,  43,  43,  44,  44,  45,  45,  46,  46,  47,  41,  48,\n",
       "          29,  49,  49,  50,  50,  51,  51,  52,  52,  53,  53,  54,  54,  55,\n",
       "          55,  56,  50,  57,  26,  21,  57,  27,  48,  29,  56,  51,  39,  34,\n",
       "          47,  42,  58,  59,  59,  60,  59,  61,  61,  62,  62,  63,  63,  64,\n",
       "          64,  65,  65,  66,  66,  67,  67,  68,  68,  69,  69,  70,  70,  71,\n",
       "          71,  72,  72,  73,  73,  74,  74,  75,  75,  76,  76,  77,  77,  78,\n",
       "          70,  61,  78,  73,  67,  62,  78,  69,  79,  80,  80,  81,  81,  82,\n",
       "          82,  83,  83,  84,  84,  85,  85,  86,  86,  87,  87,  88,  88,  89,\n",
       "          89,  90,  89,  91,  91,  92,  92,  93,  93,  94,  93,  95,  93,  96,\n",
       "          83,  97,  97,  98,  98,  99,  98, 100,  98, 101,  97, 102, 102,  80,\n",
       "          92,  86, 103, 104, 104, 105, 104, 106, 104, 107, 107, 108, 108, 109,\n",
       "         109, 110, 109, 111, 109, 112],\n",
       "        [  1,   0,   2,   1,   3,   2,   4,   3,   5,   4,   6,   5,   7,   6,\n",
       "           8,   7,   9,   6,  10,   4,  11,  10,  12,  11,  13,  12,  14,  11,\n",
       "          15,  14,  16,  15,  17,  16,  18,  15,   2,   9,   4,  18,  20,  19,\n",
       "          21,  20,  22,  21,  23,  22,  24,  23,  25,  24,  26,  25,  27,  19,\n",
       "          28,  27,  29,  28,  30,  29,  31,  30,  32,  31,  33,  32,  34,  33,\n",
       "          35,  34,  36,  35,  37,  36,  38,  37,  39,  38,  40,  31,  41,  40,\n",
       "          42,  41,  43,  42,  44,  43,  45,  44,  46,  45,  47,  46,  48,  41,\n",
       "          49,  29,  50,  49,  51,  50,  52,  51,  53,  52,  54,  53,  55,  54,\n",
       "          56,  55,  57,  50,  21,  26,  27,  57,  29,  48,  51,  56,  34,  39,\n",
       "          42,  47,  59,  58,  60,  59,  61,  59,  62,  61,  63,  62,  64,  63,\n",
       "          65,  64,  66,  65,  67,  66,  68,  67,  69,  68,  70,  69,  71,  70,\n",
       "          72,  71,  73,  72,  74,  73,  75,  74,  76,  75,  77,  76,  78,  77,\n",
       "          61,  70,  73,  78,  62,  67,  69,  78,  80,  79,  81,  80,  82,  81,\n",
       "          83,  82,  84,  83,  85,  84,  86,  85,  87,  86,  88,  87,  89,  88,\n",
       "          90,  89,  91,  89,  92,  91,  93,  92,  94,  93,  95,  93,  96,  93,\n",
       "          97,  83,  98,  97,  99,  98, 100,  98, 101,  98, 102,  97,  80, 102,\n",
       "          86,  92, 104, 103, 105, 104, 106, 104, 107, 104, 108, 107, 109, 108,\n",
       "         110, 109, 111, 109, 112, 109]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value.edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d6d5e05947be6167eb267d35887c10d38bc3ffe327cbeea7e712fb8b80c18b36"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('Graphormer-qKJ3QKr1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
